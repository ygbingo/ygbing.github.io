---
layout:     post
title:      TransE论文解读
subtitle:   Trans系列文章都源于一份TransE叙述
date:       2019-07-02
author:     Bingo
header-img: img/post-bg-transe.jpg
catalog: true
tags:
    - 知识图谱
    - NLP
    - 知识表示
---

Trans系列的主题是基于翻译模型的知识表示学习，主要用来解决知识表示和推理的问题。本文主要介绍TransE和数据集Wordnet、Freebase等。

表示学习：主要面向知识图谱中实体和关系进行表示学习，一般使用建模方法将实体和向量表示在低维稠密向量空间中，然后计算并推理，主要的应用任务有三元组提取(triplet classification)和链接预测(link prediction)。

Trans系列的源头应该就是这篇介绍的与2013年被提出的TransE模型，之后针对TransE模型的改进和补充也成为了近年来知识表示的研究热点。

> [TransE](http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf)，NIPS2013，Translating embeddings for modeling multi-relational data。<br>
> [TransH](http://xueshu.baidu.com/usercenter/paper/show?paperid=9880c513b8044b07a80a8df6cdfa0309&site=xueshu_se)，AAAI2014，Knowledge graph embedding by translating on hyperplanes。<br>
> [TransD](http://xueshu.baidu.com/usercenter/paper/show?paperid=b53cbe63d00b0060cc275f56dffdc477&site=xueshu_se)，ACL2015，Knowledge graph embedding via dynamic mapping matrix。<br>
> [TransA](https://arxiv.org/abs/1509.05490)，arXiv2015，An adaptive approach for knowledge graph embedding。<br>
> [TransG](https://arxiv.org/abs/1509.05488)，arxiv2015，A Generative Mixture Model for Knowledge Graph Embedding<br>
> [KG2E](http://xueshu.baidu.com/usercenter/paper/show?paperid=c3cfeb74056607a49ea950f57f16fde1&site=xueshu_se)，CIKM2015，Learning to represent knowledge graphs with gaussian embedding。<br>
> [TranSparse](http://xueshu.baidu.com/usercenter/paper/show?paperid=dd1ffb654749aed5c4d35bdc88311766&site=xueshu_se)，AAAI2016，Knowledge graph completion with adaptive sparse transfer matrix。<br>

**一切的Trans都源于这篇TransE**
# Translating Embeddings for Modeling Multi-relational Data
### 作者
Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran
### 解决的问题
- 主要解决将多关系数据中，将实体和关系映射到低维向量空间中的问题；
### 目的
- 目的是提出一个易训练的通用模型，利用较少量参数的同时，可以将模型拓展到非常庞大的高维数据库中；
### 方法
- TransE
给定一个三元组数据集S，每个三元组用(h,l,t)表示，其中h，t分别是头实体和尾实体，l是h和t的关系，目标是希望满足公式：h+l=t
目标函数采用了常见的margin-based ranking criterion
### 实验
- 数据集
    - Wordnet<br>
        这个数据集用来产生直观且可用的字典和词库，并支持自动文本分析。它的实体(entities)对应词义(word_senses)，关系(relationships)定义了两个词义间的关系(lexical relations)。例如一个三元组：(_score_NN_1, _hypernym, _evaluation_NN_1) 或者 (_score_NN_2, _has_part, _musical_notation_NN_1)。
    - Freebase<br>
        Freebase是一个根据现实生活自更新的庞大数据库，有将近12亿个三元组和超过8千万的实体(截至2013年)，TransE论文基于Freebase创建了两个数据集。首先，基于wikilinks数据库和freebase的部分实体和关系建立了一个小型数据集FB15k，并且溢出了其中可反向的三元组，如'!/people/person/nationality'和'/people/person/nationality'，该数据集包括592,213个三元组，共包括14951个实体和1345个关系。另外还创建了一个高维的数据集FB1M，包含超过170亿个三元组，共1亿个实体和2.5万个关系。
- 对比方法
    - Unstructured<br>
        这是TransE的版本之一，它将数据视为mono-relational，并且将所有的translations视为0。在参考文献【2】中同样作为baseline
    - RESCAL<br>
        这是在文献[11](http://xueshu.baidu.com/usercenter/paper/show?paperid=707aa2c712e6a058a35724f692f8fc6e&site=xueshu_se),[12](http://xueshu.baidu.com/usercenter/paper/show?paperid=7a91fe5aca731275fba16bef538f5662&site=xueshu_se)中被提出的基于集体矩阵分解的模型
    - SE<br>
        这是在文献[3](http://www.utc.fr/~bordesan/dokuwiki/_media/en/bordes11snowbird.pdf)中被提出的基于能量的模型
    - SME(LINEAR)/SME(BILINEAR)<br>
        文献[2](https://arxiv.org/abs/1301.3485v2)
    - LFM<br>
        文献[6](http://xueshu.baidu.com/usercenter/paper/show?paperid=7bd1fe7364cba617444ef352c7184d77&site=xueshu_se)
- 评价指标
    - link-prediction：
        - 将一个正确的三元组a中的头实体或者尾实体，依次替换为整个知识库中的所有其它实体，也就是会产生n个三元组。
        - 分别对上述n个三元组计算其能量值，在transE中，就是计算h+r-t的值。这样可以得到n个能量值，分别对应上述n个三元组。
        - 对上述n个能量值进行升序排序。
        - 记录三元组a的能量值排序后的序号。
        - 对所有的正确的三元组重复上述过程。
        - 每个正确三元组的能量值排序后的序号求平均，得到的值我们称为Mean Rank。
        - 计算正确三元组的能量排序后的序号小于10的比例，得到的值我们称为Hits@10。
        - Mean Rank：一般来说，越小越好
        - Hits@10：一般来说，越大越好
### 结论与未来工作
- 结论<br>
TransE主要提出一种学习KB embedding的新方法，主要关注点在：1、模型最少参数化；2、主要层次关系的表示，通过实验验证，发现该效果非常有效；另外，通过在1-1，1-m，m-1，m-m的实验分析，发现TransE在模拟所有关系模型上表现良好。
- 未来工作<br>
未来的工作可以进一步分析这个模型，并且还专注于在更多任务中利用它，特别是诸如学习[8]启发的单词表示的应用程序。将KB与文本组合在一起是另一个重要方向，另外还可以将TransE插入到从文本中提取关系的框架中。
