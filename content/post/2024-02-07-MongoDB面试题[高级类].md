---
title: "2024 02 07 MongoDB面试题[高级类]"
date: 2024-02-07T21:39:23+08:00
draft: false
tags:
    - interview
    - mongoDB
---

# 在MongoDB中如何搜索
“find”方法用于在 MongoDB 中执行查询。查询返回集合中的文档子集，从没有文档到整个集合。返回哪些文档由 find 的第一个参数决定，该参数是指定查询条件的文档。

例如：如果我们有一个想要匹配的字符串，例如带有值“alice”的“username”键，我们将使用该键/值对：
``` shell
> db.users.find({"username" : "alice"})
```
The `find` method is used to perform queries in MongoDB. Querying returns a subset of documents in a collection, from no documents at all to the entire collection. Which documents get returned is determined by the first argument to find, which is a document specifying the query criteria.

For example: If we have a string we want to match, such as a "username" key with the value "alice", we use that key/value pair instead:
``` shell
> db.users.find({"username" : "alice"})
```

# 解释一下索引(Indexing)

在 MongoDB 中，索引有助于有效地解决查询。索引的作用是以易于遍历的形式存储一小部分数据集。索引存储特定字段或字段集的值，按索引中指定的字段值排序。
MongoDB 的索引与典型关系数据库索引的工作方式几乎相同。
索引查看包含内容引用的有序列表。这些反过来又使 MongoDB 的查询速度提高了几个数量级。要创建索引，请使用 `createIndex` 集合方法。
例如：
``` shell
> db.users.find({"username": "user101"}).explain("executionStats")
```
这里，`executionStats`模式帮助我们理解使用索引来满足查询的效果

In MongoDB, indexes help in efficiently resolving queries. What an Index does is that it stores a small part of the data set in a form that is easy to traverse. The index stores the value of the specific field or set of fields, ordered by the value of the field as specified in the index. 
MongoDB’s indexes work almost identically to typical relational database indexes.

Indexes look at an ordered list with references to the content. These in turn allow MongoDB to query orders of magnitude faster. To create an index, use the `createIndex` collection method.

For example:
``` shell
> db.users.find({"username": "user101"}).explain("executionStats")
```
Here, `executionStats` mode helps us understand the effect of using an index to satisfy queries


# MongoDB中的地理空间索引是什么(What are Geospatial Indexes in MongoDB?)

MongoDB 有两种类型的地理空间索引：2dsphere 和 2d。 2dsphere 索引适用于基于 WGS84 基准对地球表面进行建模的球形几何形状。该基准将地球表面建模为扁球体，这意味着两极有一定程度的扁平化。因此，使用 2sphere 索引进行距离计算会考虑地球的形状，并且比 2d 索引更准确地处理两个城市之间的距离。对存储在二维平面上的点使用二维索引。

2dsphere 允许您以 GeoJSON 格式指定点、线和多边形的几何形状。一个点由一个二元素数组给出，表示[longitude, latitude]：

MongoDB has two types of geospatial indexes: 2dsphere and 2d. 2dsphere indexes work with spherical geometries that model the surface of the earth based on the WGS84 datum. This datum model the surface of the earth as an oblate spheroid, meaning that there is some flattening at the poles. Distance calculations using 2sphere indexes, therefore, take the shape of the earth into account and provide a more accurate treatment of distance between, for example, two cities, than do 2d indexes. Use 2d indexes for points stored on a two-dimensional plane.

2dsphere allows you to specify geometries for points, lines, and polygons in the GeoJSON format. A point is given by a two-element array, representing [longitude, latitude]:
``` json
{
   "name" : "New York City",
   "loc" : {
       "type" : "Point",
       "coordinates" : [50, 2]
   }
}
```
A line is given by an array of points:
``` json
{
   "name" : "Hudson River",
   "loc" : {
       "type" : "LineString",
       "coordinates" : [[0,1], [0,2], [1,2]]
   }
}
```


# 解释一下分片(Sharding) 

分片是跨机器分割数据的过程。我们有时也使用术语“分区”来描述这个概念。通过在每台机器上放置数据子集，我们可以存储更多数据并处理更多负载，而不需要更大或更强大的机器。
下图中，RS0和RS1是分片。 MongoDB 的分片允许您创建由许多机器（分片）组成的集群，并在它们之间分解集合，将数据子集放在每个分片上。这允许您的应用程序的增长超出独立服务器或副本集的资源限制。

Sharding is the process of splitting data up across machines. We also use the term “partitioning” sometimes to describe this concept. We can store more data and handle more load without requiring larger or more powerful machines, by putting a subset of data on each machine.
In the figure below, RS0 and RS1 are shards. MongoDB’s sharding allows you to create a cluster of many machines (shards) and break up a collection across them, putting a subset of data on each shard. This allows your application to grow beyond the resource limits of a standalone server or replica set.

# 解释一下 MongoDB 中的 SET 修饰符？

如果字段的值尚不存在，则“$set”设置该值。这对于更新架构或添加用户定义的键非常有用。

If the value of a field does not yet exist, the "$set" sets the value. This can be useful for updating schemas or adding user-defined keys.

``` shell
> db.users.findOne()
{
   "_id" : ObjectId("4b253b067525f35f94b60a31"),
   "name" : "alice",
   "age" : 23,
   "sex" : "female",
   "location" : "India"
}

> db.users.updateOne({"_id" : 
ObjectId("4b253b067525f35f94b60a31")},
... {"$set" : {"favorite book" : "Start with Why"}}) 
```

# 解释一下事务(Transactions)

事务是数据库中的处理逻辑单元，包括一个或多个数据库操作，可以是读取或写入操作。事务在 MongoDB 中提供了一个有用的功能来确保一致性。
MongoDB 提供了两个 API 来使用事务。
- 核心API：与关系数据库的语法类似（例如start_transaction和commit_transaction）
- 回调 API：这是使用事务的推荐方法。它启动一个事务，执行指定的操作，然后提交（或因错误而中止）。它还自动合并“TransientTransactionError”和“UnknownTransactionCommitResult”的错误处理逻辑

A transaction is a logical unit of processing in a database that includes one or more database operations, which can be read or write operations. Transactions provide a useful feature in MongoDB to ensure consistency.

MongoDB provides two APIs to use transactions. 

- Core API: It is a similar syntax to relational databases (e.g., start_transaction and commit_transaction)
- Call-back API: This is the recommended approach to using transactions. It starts a transaction, executes the specified operations, and commits (or aborts on the error). It also automatically incorporates error handling logic for "TransientTransactionError" and"UnknownTransactionCommitResult"

``` python
from pymongo import MongoClient

# 创建 MongoClient 实例
client = MongoClient()

# 创建数据库和集合
db = client.test
collection = db.test

# 开始事务
with client.start_session() as session:
    # 在事务范围内执行操作
    collection.insert_one({"name": "John Doe"}, session=session)
    collection.update_one({"name": "John Doe"}, {"$set": {"age": 30}}, session=session)

# 提交事务
session.commit_transaction()
```

# Mongo的图表(Charts)是什么

MongoDB Charts 是 MongoDB 中用于数据可视化的新集成工具。
MongoDB Charts 提供了使用 MongoDB 数据库中的数据创建可视化效果的最佳方法。
它允许用户从数据库执行快速数据表示，而无需使用 Java 或 Python 等编程语言编写代码。

MongoDB Charts is a new, integrated tool in MongoDB for data visualization.

MongoDB Charts offers the best way to create visualizations using data from a MongoDB database.
It allows users to perform quick data representation from a database without writing code in a programming language such as Java or Python.

``` python
# 创建一个 MongoClient 实例
client = MongoClient()

# 创建数据库和集合
db = client.test
collection = db.test

# 创建图表
chart = Charts(db, collection)

# 设置图表类型
chart.set_type("line")

# 设置数据源
chart.set_data_source(collection)

# 设置图表选项
chart.set_title("Test Chart")
chart.set_x_axis("name")
chart.set_y_axis("age")

# 预览图表
chart.preview()

# 保存图表
chart.save()
```

# 解释一下Mongo的聚合框架(Aggregation Framework)
- 聚合框架是 MongoDB 中的一组分析工具，允许您对一个或多个集合中的文档进行分析。
- 聚合框架基于管道的概念。通过聚合管道，我们从 MongoDB 集合获取输入，并将该集合中的文档传递到一个或多个阶段，每个阶段对其输入执行不同的操作（见下图）。每个阶段都将其之前的阶段作为输出作为输入。所有阶段的输入和输出都是文档——文档流。
The aggregation framework is a set of analytics tools within MongoDB that allow you to do analytics on documents in one or more collections.
The aggregation framework is based on the concept of a pipeline. With an aggregation pipeline, we take input from a MongoDB collection and pass the documents from that collection through one or more stages, each of which performs a different operation on its inputs (See figure below). Each stage takes as input whatever the stage before it produced as output. The inputs and outputs for all stages are documents—a stream of documents.

- 聚合管道阶段
以下是 MongoDB 聚合中常用的阶段：
``` shell
$match：根据条件过滤文档
$project：选择要输出的字段
$group：按字段分组并计算聚合值
$sort：按字段排序
$limit：限制输出文档的数量
$skip：跳过指定数量的文档
$unwind：将数组解开为单独的文档
$lookup：从另一个集合中查找并关联文档
$facet：将管道分成多个并行管道
```

- 聚合执行流程

1. 文档从集合中流入管道。
2. 文档流依次经过每个阶段。
3. 每个阶段对文档流进行转换。
4. 最终结果文档输出到结果集合或游标。

- 聚合示例

以下是一个简单的聚合示例，用于计算集合中所有文档的平均年龄：
``` shell
db.collection.aggregate([
  { $match: { age: { $gt: 18 } } },
  { $group: { _id: null, averageAge: { $avg: "$age" } } }
])
```
该聚合管道首先使用 `$match` 阶段过滤年龄大于 18 岁的文档。然后，它使用 `$group` 阶段计算所有文档的平均年龄。

# 什么是Mongo的副本集(Replica Set)

为了在多个服务器上保留相同的数据副本，我们使用复制。建议用于所有生产部署。使用复制来保持应用程序运行和数据安全，即使一台或多台服务器发生问题也是如此。

这种复制可以通过 MongoDB 的副本集来创建。副本集是一组服务器，其中一个主服务器负责写入，多个辅助服务器保留主服务器数据的副本。如果主节点崩溃，辅助节点可以从它们之间选举一个新的主节点

To keep identical copies of your data on multiple servers, we use replication. It is recommended for all production deployments. Use replication to keep your application running and your data safe, even if something happens to one or more of your servers.

Such replication can be created by a replica set with MongoDB. A replica set is a group of servers with one primary, the server taking writes, and multiple secondaries, servers that keep copies of the primary’s data. If the primary crashes, the secondaries can elect a new primary from amongst themselves. 

- Replica Set 的主要优点包括：

    - 高可用性：即使主节点发生故障，应用程序也能继续运行。
    - 数据一致性：所有节点都保存相同的数据副本。
    - 读扩展性：可以通过增加从节点的数量来提高读取性能。
    - 写入扩展性：可以通过使用多个主节点来提高写入性能。

- Replica Set 的工作原理如下：

    - 所有写操作都发送到主节点。
    - 主节点将写操作应用到其数据副本上。
    - 主节点将写操作异步复制到从节点。
    - 从节点将写操作应用到其数据副本上。

- 如果主节点发生故障，则从节点会进行选举以选出一个新的主节点。 选举过程如下：

1. 所有从节点都投票给自己。
2. 得票最多的从节点成为新的主节点。
3. 新的主节点开始接受写操作。

- Replica Set 的常见配置包括：

- 3 个节点：这是最常见的配置，它提供良好的可用性和数据一致性。
- 2 个节点：这种配置提供较低的成本，但可用性较低。
- 4 个或更多节点：这种配置提供更高的可用性和数据一致性，但成本也更高。

# 解释Mongo的复制架构(Replication Architecture)

MongoDB 使用 Replica Sets 来确保数据的冗余和可用性。以下是其架构以及如何保证数据一致性的详细解释：

- 核心组件：

    - 主节点： 负责处理所有写操作的单个节点。它是您的数据的“真相来源”。
    - 从节点： 主节点的副本，接收并存储数据的副本。它们无法直接处理写入，但可以提供读取请求。
    - 仲裁者（可选）： 仅投票的成员，不存储数据，但有助于选举过程。

- 数据复制过程：
    - 写入： 所有写入首先进入主节点。
    - 操作日志： 主节点将操作记录在专用的“操作日志”(oplog)中。
    - 复制： 操作日志会持续复制到所有从节点。
    - 从节点更新： 每个从节点在其自身数据上重放操作日志更新，保持一致性。

- 数据一致性：
    - 最终一致性： 从节点上的数据最终会与主节点保持一致。但是，根据网络和系统负载，可能存在短暂的延迟。
    - 读取您自己的写入： 从主节点读取始终反映最新数据。
    - 写入关注： 您可以配置“写入关注”以指定在写入被视为完成之前，应该有多少个从节点确认它，增强一致性保证。

- 高可用性：
    - 如果主节点失败，从节点将参与选举以选出新的主节点。
    - 新的主节点将以最小的停机时间恢复操作，确保持续的数据访问。

- 优点：
    - 提高数据可用性： 如果一个节点失败，其他节点可以提供服务。
    - 灾难恢复： 副本在发生灾难性故障时充当备份。
    - 读取扩展性： 将读取负载分散到多个节点以提高性能。

- 其他注意事项：
    - 您可以配置多个从节点甚至多个主节点，以增强冗余性和可扩展性。
    - 复制会带来一些开销，因此请根据您的需求选择平衡可用性、性能和成本的配置。

MongoDB utilizes Replica Sets to ensure data redundancy and availability. Here's a breakdown of its architecture and how it guarantees data consistency:

Core Components:

Primary Node: Single node responsible for processing all write operations. It acts as the "source of truth" for your data.
Secondary Nodes: Replicas of the primary node that receive and store copies of the data. They can't handle writes directly but serve read requests.
Arbiter (Optional): Vote-only member that doesn't store data but helps with election process.
Data Replication Process:

Writes: All writes go to the primary node first.
Oplog: The primary logs operations in a dedicated "oplog" (operations log).
Replication: The oplog is continuously replicated to all secondaries.
Secondary Updates: Each secondary replays the oplog updates on its own data, maintaining consistency.
Data Consistency:

Eventual Consistency: Data on secondaries eventually becomes consistent with the primary. However, there might be a short lag depending on network and system load.
Read Your Own Writes: Reads from the primary always reflect the latest data.
Write Concerns: You can configure "write concerns" to specify how many secondaries should acknowledge a write before it's considered complete, enhancing consistency guarantees.
High Availability:

If the primary fails, secondaries participate in an election to elect a new one.
The new primary resumes operations with minimal downtime, ensuring continuous data access.
Benefits:

Increased Data Availability: If one node fails, others can serve requests.
Disaster Recovery: Replicas act as backups in case of catastrophic failure.
Read Scalability: Spread read load across multiple nodes for better performance.
Additional Notes:

You can configure multiple secondaries and even multiple primaries for enhanced redundancy and scalability.
Replication introduces some overhead, so choose a configuration that balances availability, performance, and cost based on your needs.
I hope this explanation clarifies the Replication Architecture in MongoDB! Feel free to ask any further questions you might have.

# Mongo备份和恢复常用工具

The mongo shell does not include functions for exporting, importing, backup, or restore. However, MongoDB has created methods for accomplishing this, so that no scripting work or complex GUIs are needed. For this, several utility scripts are provided that can be used to get data in or out of the database in bulk. These utility scripts are:

- mongoimport
    - 将数据导入到 MongoDB 数据库中。
    - 支持 JSON、CSV、TSV 等格式的数据导入。
    - 可以指定导入的数据库、集合、字段等。
    ``` shell
    mongoimport --db test --collection users --file users.json
    ```
- mongoexport
    - 将 MongoDB 数据库中的数据导出到文件。
    - 支持 JSON、CSV、TSV 等格式的数据导出。
    - 可以指定导出的数据库、集合、字段、查询条件等。
    ``` shell
    mongoexport --db test --collection users --file users.json --query '{age: {$gt: 18}}'
    ```
- mongodump
    - 将 MongoDB 数据库备份到文件。
    - 导出的是 BSON 格式的数据，可以用于恢复数据库。
    - 可以指定备份的数据库、集合等。
    ``` shell
    mongodump --db test --collection users --out users.bson
    ```
- mongorestore
    - 将 MongoDB 数据库从备份文件中恢复。
    - 可以恢复整个数据库或部分集合。
    - 可以指定恢复的数据库、集合等。
    ``` shell
    mongorestore --db test --collection users --file users.bson
    ```